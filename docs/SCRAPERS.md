# Scrapers Especializados para Fontes de Not√≠cias Financeiras

Este documento descreve os scrapers especializados para as 5 principais fontes de not√≠cias financeiras do Brasil.

## üì∞ Fontes Suportadas

### 1. InfoMoney (`infomoney_scraper.py`)
- **URL**: https://www.infomoney.com.br
- **Categorias**: mercados, economia, investimentos, negocios, carreira
- **Caracter√≠sticas**: Site JavaScript-heavy, URLs longas com categorias
- **Teste**: `test_infomoney_scraper.py`

### 2. Valor Econ√¥mico (`valor_scraper.py`)
- **URL**: https://valor.globo.com
- **Categorias**: financas, empresas, mercados, mundo, politica, brasil
- **Caracter√≠sticas**: Data inclusa na URL (formato: /ano/mes/dia/)
- **Teste**: `test_valor_scraper.py`

### 3. Bloomberg Brasil (`bloomberg_scraper.py`)
- **URL**: https://www.bloomberg.com.br
- **Categorias**: mercados, economia, politica, empresas
- **Caracter√≠sticas**: Arquitetura internacional Bloomberg
- **Teste**: `test_bloomberg_scraper.py`

### 4. E-Investidor/Estad√£o (`einvestidor_scraper.py`)
- **URL**: https://einvestidor.estadao.com.br
- **Categorias**: investimentos, mercados, colunas, acoes, fundos-imobiliarios
- **Caracter√≠sticas**: Foco em educa√ß√£o financeira
- **Teste**: `test_einvestidor_scraper.py`

### 5. Money Times (`moneytimes_scraper.py`)
- **URL**: https://www.moneytimes.com.br
- **Categorias**: Homepage principal
- **Caracter√≠sticas**: URLs com c√≥digos √∫nicos
- **Teste**: `test_moneytimes_scraper.py`

## üöÄ Uso R√°pido

### Exemplo Individual

```python
from news_scraper.infomoney_scraper import scrape_infomoney

# Coletar URLs de artigos
urls = scrape_infomoney(category='mercados', limit=10, headless=True)
print(f"Coletadas {len(urls)} URLs")
```

### Exemplo com Extra√ß√£o Completa

```python
from news_scraper.browser import BrowserConfig, ProfessionalScraper
from news_scraper.valor_scraper import ValorScraper
from news_scraper.extract import extract_article_metadata

config = BrowserConfig(headless=True)

with ProfessionalScraper(config) as scraper:
    valor = ValorScraper(scraper)
    
    # Coletar URLs
    urls = valor.get_financas_articles(limit=5)
    
    # Extrair metadados de cada artigo
    for url in urls:
        scraper.get_page(url, wait_time=3)
        article = extract_article_metadata(url, scraper.driver)
        
        print(f"T√≠tulo: {article.title}")
        print(f"Data: {article.date_published}")
        print(f"Autor: {article.author}")
        print(f"Texto: {len(article.text)} caracteres")
```

### Exemplo Multi-Fonte

```python
from news_scraper.browser import BrowserConfig, ProfessionalScraper
from news_scraper import (
    InfoMoneyScraper,
    ValorScraper,
    BloombergScraper,
    EInvestidorScraper,
    MoneyTimesScraper,
)

config = BrowserConfig(headless=True)

with ProfessionalScraper(config) as scraper:
    # InfoMoney
    infomoney = InfoMoneyScraper(scraper)
    urls_im = infomoney.get_mercados_articles(limit=5)
    
    # Valor
    valor = ValorScraper(scraper)
    urls_valor = valor.get_financas_articles(limit=5)
    
    # Bloomberg
    bloomberg = BloombergScraper(scraper)
    urls_bb = bloomberg.get_mercados_articles(limit=5)
    
    # E-Investidor
    einvestidor = EInvestidorScraper(scraper)
    urls_ei = einvestidor.get_investimentos_articles(limit=5)
    
    # Money Times
    moneytimes = MoneyTimesScraper(scraper)
    urls_mt = moneytimes.get_latest_articles(limit=5)
    
    # Consolidar
    all_urls = urls_im + urls_valor + urls_bb + urls_ei + urls_mt
    print(f"Total: {len(all_urls)} URLs coletadas")
```

## üß™ Testes

Todos os scrapers possuem testes que validam:

1. ‚úÖ **Coleta de URLs**: Verifica se as URLs s√£o coletadas corretamente
2. ‚úÖ **Filtros de Categoria**: Valida se os filtros funcionam
3. ‚úÖ **Extra√ß√£o de Metadados**: Garante que todos os campos essenciais s√£o extra√≠dos
4. ‚úÖ **Taxa de Sucesso**: Verifica se pelo menos 80% dos artigos t√™m metadados completos

### Executar Testes

```bash
# Todos os testes de scrapers
pytest tests/test_*_scraper.py -v

# Teste espec√≠fico
pytest tests/test_infomoney_scraper.py -v

# Com output detalhado
pytest tests/test_valor_scraper.py -v -s
```

## üìä Metadados Garantidos

Cada scraper garante a extra√ß√£o dos seguintes campos:

- **url**: URL completa do artigo
- **title**: T√≠tulo completo da not√≠cia
- **date_published**: Data de publica√ß√£o (datetime)
- **author**: Autor(es) quando dispon√≠vel
- **text**: Texto completo do artigo
- **source**: Nome da fonte
- **scraped_at**: Data/hora da coleta
- **language**: Idioma do conte√∫do
- **extra**: Metadados adicionais espec√≠ficos

### Import√¢ncia da Data

**A data de publica√ß√£o √© cr√≠tica** para an√°lises financeiras. Todos os scrapers foram projetados para:

1. Extrair datas confi√°veis dos metadados HTML
2. Validar formatos de data
3. Fallback para data na URL quando dispon√≠vel (ex: Valor)
4. Garantir timezone correto (America/Sao_Paulo)

## üéØ Demonstra√ß√£o

Execute o script de demonstra√ß√£o para ver todos os scrapers em a√ß√£o:

```bash
python -m scripts.demo_all_sources
```

Este script:
- Coleta URLs de cada fonte
- Extrai metadados completos
- Valida todos os campos
- Mostra estat√≠sticas de sucesso

## üõ†Ô∏è Configura√ß√£o

### Par√¢metros Comuns

Todos os scrapers aceitam:

- **category**: Categoria espec√≠fica ou None para homepage
- **limit**: N√∫mero m√°ximo de URLs (padr√£o: 20)
- **headless**: Executar browser invis√≠vel (padr√£o: True)

### Customiza√ß√£o

```python
from news_scraper.browser import BrowserConfig

# Configura√ß√£o customizada
config = BrowserConfig(
    headless=True,
    user_agent="seu-user-agent",
    window_size=(1920, 1080)
)
```

## ‚ö†Ô∏è Considera√ß√µes

1. **Rate Limiting**: Respeite os limites de cada site
2. **Robots.txt**: Verifique permiss√µes antes de fazer scraping em massa
3. **Termos de Uso**: Consulte os termos de servi√ßo de cada portal
4. **Performance**: Sites JavaScript-heavy podem ser lentos
5. **Manuten√ß√£o**: Estruturas HTML podem mudar com atualiza√ß√µes

## üìà Performance

Tempos m√©dios (headless, 3 artigos):

- InfoMoney: ~15s
- Valor: ~20s
- Bloomberg: ~18s
- E-Investidor: ~12s
- Money Times: ~10s

## üîÑ Atualiza√ß√µes

Para manter os scrapers funcionando:

1. Execute os testes regularmente
2. Monitore mudan√ßas nas estruturas HTML
3. Ajuste seletores CSS/XPath conforme necess√°rio
4. Atualize testes quando necess√°rio

## üìù Licen√ßa

Veja LICENSE no reposit√≥rio principal.
